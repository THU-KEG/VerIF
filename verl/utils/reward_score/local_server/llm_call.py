import re
from build_model import APIModel

api_url=""
model_name=""
api_model = APIModel(api_url, model_name)


def generate_chat(messages, max_tokens=128, temperature=0.0):
    response = api_model.generate_chat(messages, max_tokens, temperature)
    return response.strip()


def extract_chat(messages, max_tokens=128, temperature=0.0):
    response = api_model.generate_chat(messages, max_tokens, temperature)
    return response.strip()


prompt_template = """
è¯·åˆ¤æ–­ä»¥ä¸‹æ–‡æœ¬æ˜¯å¦æ»¡è¶³ç»™å®šçš„çº¦æŸï¼Œä»…å›ç­”æ˜¯æˆ–å¦ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚


åŸå§‹æŒ‡ä»¤ï¼š$I$

æ–‡æœ¬ï¼š$R$

çº¦æŸï¼š$C$

åŸå§‹æŒ‡ä»¤æè¿°äº†åŸºæœ¬çš„ä»»åŠ¡ä¿¡æ¯ï¼Œç»™å®šçš„çº¦æŸä»‹ç»äº†åº”è¯¥æ»¡è¶³çš„å…·ä½“çš„ä¸€ä¸ªçº¦æŸã€‚
è¯·åˆ¤æ–­ä»¥ä¸‹æ–‡æœ¬æ˜¯å¦æ»¡è¶³ç»™å®šçš„è¿™ä¸ªçº¦æŸï¼ˆä»…ä»…åˆ¤æ–­æ˜¯å¦æ»¡è¶³ç»™å®šçš„çº¦æŸï¼‰ï¼Œä»…å›ç­”æ˜¯æˆ–å¦ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚
"""


def llm_judge(instruction, response, constraint):
    if isinstance(response, list):
        response = "\n\n".join(response)
    prompt = prompt_template.replace("$R$", response).replace("$C$", constraint).replace("$I", instruction)
    data = [
        {"role": "user", "content": prompt}
    ]
    response = generate_chat(data)

    return response[0] == "æ˜¯"


def llm_extract(instruction, response, specific_prompt):
    prompt_suffix = "\nè¯·ç›´æ¥è¾“å‡ºæ–‡æœ¬ä¸­çš„åŸæ–‡ä¿¡æ¯ï¼Œä¸è¦æ”¹å†™ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„ä¿¡æ¯ã€‚"

    prompt = f"æ–‡æœ¬ï¼š{response}\næŠ½å–è¦æ±‚ï¼š{specific_prompt}" + prompt_suffix
    data = [
        {"role": "user", "content": prompt}
    ]
    response = extract_chat(data, max_tokens=1024)
    return response


def extract_score(text):
    match = re.search(r'\[\[(\d+)\]\]', text)
    try:
        return int(match.group(1))
    except:
        return 0


def llm_score(instruction, response, checkers):
    prompt = f"""
    è¯·åˆ¤æ–­ç»™å®šçš„å›å¤æ˜¯å¦éµå¾ªæŒ‡ä»¤ä¸­çš„çº¦æŸï¼Œæ¯”å¦‚é•¿åº¦ã€é£æ ¼ã€æ ¼å¼ç­‰çº¦æŸã€‚
    
    [æŒ‡ä»¤]
    {instruction}

    [å›å¤]
    {response}

    [çº¦æŸ]
    {checkers}

    è¯·åˆ¤æ–­ç»™å®šçš„å›å¤æ˜¯å¦éµå¾ªæŒ‡ä»¤ä¸­çš„çº¦æŸï¼Œæ¯”å¦‚é•¿åº¦ã€é£æ ¼ã€æ ¼å¼ç­‰çº¦æŸã€‚
    è¯·åœ¨å›ç­”çš„æœ€å¼€å§‹ç”¨[[score]]æ ¼å¼è¾“å‡ºä½ çš„åˆ†æ•°ã€‚
    å¦‚æœéµå¾ªæ‰€æœ‰çš„çº¦æŸï¼Œè¯·è¾“å‡º[[1]]ï¼Œå¦åˆ™è¾“å‡º[[0]]
    """
    data = [
        {"role": "user", "content": prompt}
    ]
    response = generate_chat(data, max_tokens=4096)
    score = extract_score(response)
    return score



if __name__ == "__main__":
    result = llm_judge(
        "What is the speed of light, and how does it compare to the speed of sound in a vacuum? Please answer with a tone of excitement and wonder.The word 'light' should appear at least 3 times, and your response should contain exactly 3 sentences.",
        "Oh, the speed of light is a mind-blowing marvel of the universe, traveling at a staggering 299,792,458 meters per second (m/s)! ğŸŒŸ In comparison, the speed of sound in a vacuum is non-existent because sound needs a medium to travel, whereas light races through the void with unparalleled grace and swiftness. Imagine the thrill of light zooming across the cosmos, effortlessly outpacing any sound, and illuminating the mysteries of space with its incredible speed!",
        "Your response should contain exactly 3 sentences",
    )
    print(result)

    


